{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit User Vizualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searches Reddit for a single user and optionally keywords using the PushShift API via the python library psaw\n",
    "\n",
    "# Designed to work with in \"Appmode\": click the Appmode button in the toolbar, or replace 'notebooks' with 'apps' this notebook's URL\n",
    "\n",
    "# Appmode documentation: https://github.com/oschuett/appmode\n",
    "# PSAW Documentation: https://github.com/dmarx/psaw\n",
    "# PushShift API Reference: https://pushshift.io/api-parameters/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Default Configuration\n",
    "# Aggregate by month. 'D' for day.\n",
    "import datetime as dt\n",
    "\n",
    "agg_level = 'M'\n",
    "default_chart_height = 800\n",
    "default_chart_width = 1200\n",
    "score_bubble_height=1600\n",
    "maxVisibleRows = 25\n",
    "default_min_date = dt.date(2019, 1, 1)\n",
    "default_max_date = dt.date(2020, 1, 1)\n",
    "default_limit = 10000\n",
    "author=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports and options setting\n",
    "from collections import OrderedDict\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# pandas, numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# psaw\n",
    "from psaw import PushshiftAPI\n",
    "api = PushshiftAPI()\n",
    "\n",
    "# plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly import express as px\n",
    "\n",
    "# qgrid\n",
    "import qgrid\n",
    "qgrid.enable()\n",
    "\n",
    "# bokeh\n",
    "from bokeh.io import push_notebook, show, output_notebook\n",
    "from bokeh.layouts import row\n",
    "from bokeh.plotting import figure,show\n",
    "from bokeh.models import ColumnDataSource, OpenURL, TapTool, HoverTool, Jitter, Panel, Tabs\n",
    "from bokeh.transform import factor_cmap, factor_mark, jitter\n",
    "from bokeh.models.ranges import FactorRange\n",
    "import bokeh.resources\n",
    "\n",
    "output_notebook(bokeh.resources.INLINE,verbose=False, hide_banner=True)\n",
    "\n",
    "# ipywidgets\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interactive, interact, HBox, Layout,VBox, Select, interact_manual, Output, Tab\n",
    "from IPython.display import FileLink, FileLinks\n",
    "from IPython.core.display import display, HTML, clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change default display\n",
    "display(HTML(\"<style>.container { width:100% !important; } .header {padding-top:0px !important;} #notebook {padding-top:0px !important;} #notebook-container {padding:0px !important;}</style>\"))\n",
    "#display(HTML('<script> var x = document.getElementById(\"header\");x.remove(x.selectedIndex);'))\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "def score_by_subreddit_and_time(df,height=default_chart_height,width=default_chart_width):\n",
    "    df['abs_score'] = np.abs(df['score'])\n",
    "    df['is_negative_score'] = (df['score']<0)\n",
    "    return(px.scatter(df,x='created_utc',y='subreddit',color='post_type',size='abs_score',hover_name='text',symbol='is_negative_score',width=chart_width,height=chart_height))\n",
    "\n",
    "def link_domains_reporting_over_time (df,height=default_chart_height,width=default_chart_width):\n",
    "    df['domain'] = None\n",
    "    df.loc[df['url'].notnull(),'domain'] = [urlparse(i).netloc for i in df[df['url'].notnull()]['url'].values]\n",
    "    df['domain'] = df['domain'].str.replace('^www.','')\n",
    "    df = df.merge(bias_df,on='domain',how='left')\n",
    "    df['reporting'] = df['reporting'].fillna('UNKNOWN')\n",
    "    df['day'] = df['created_utc'].dt.floor('D')\n",
    "    df['month'] = df['created_utc'].dt.to_period('M').dt.to_timestamp()\n",
    "    plot_data = df.groupby(['day','reporting']).agg(len).reset_index()\n",
    "    plot_data = plot_data[['day','reporting','score']]\n",
    "    plot_data.columns = ['day','reporting','count']\n",
    "    return(px.bar(plot_data,x='day',y='count',color='reporting',width=chart_width,height=chart_height))\n",
    "\n",
    "def plot_karma_by_subreddit(times, lg=False,height=default_chart_height,width=default_chart_width):\n",
    "    subs = times.subreddit.value_counts().head(10).index.tolist()\n",
    "    times = times[times.subreddit.isin(subs)].copy()\n",
    "    if lg:\n",
    "        times['log_score'] = np.sign(times.score)*np.log2(np.abs(times.score)+1)\n",
    "        return px.violin(times, y=\"log_score\", x=\"subreddit\", color='post_type', box=True, points=\"all\",width=width,height=height)\n",
    "    else:\n",
    "        return px.violin(times, y=\"score\", x=\"subreddit\", color='post_type', box=True, points=\"all\",width=width,height=height)\n",
    "\n",
    "\n",
    "def author_to_karma_chart(data,width=default_chart_width,height=default_chart_height):\n",
    "    df1 = data[data['post_type']=='comment']\n",
    "    df1 = df1.sort_values('created_utc').reset_index()\n",
    "    df2 = data[data['post_type']=='submission']\n",
    "    df2 = df2.sort_values('created_utc').reset_index()\n",
    "    df1['comment_score'] = df1['score'].cumsum()\n",
    "    df2['submission_score'] = df2['score'].cumsum()\n",
    "\n",
    "    times = pd.concat([df1,df2],ignore_index=True,sort=False)\n",
    "    times = times.sort_values('created_utc').reset_index()\n",
    "\n",
    "    times['submission_karma'] = times['submission_score']\n",
    "    times['comment_karma'] = times['comment_score']\n",
    "    times = times.fillna(0)\n",
    "    times['karma'] = times['comment_karma']\n",
    "    times.loc[times['post_type']=='submission','karma'] = times.loc[times['post_type']=='submission','submission_karma']\n",
    "    return(px.line(times,width=width,height=height,x='created_utc',y='karma',color='post_type'))\n",
    "\n",
    "def links_over_time (times,height=default_chart_height,width=default_chart_width, agg_level = agg_level):\n",
    "    times = times.sort_values('created_utc').reset_index()\n",
    "    times = times[times.domain!='']\n",
    "    times.domain = times.domain.str.replace('/r/[a-zA-Z0-9_\\-]+(.*)$','')\n",
    "    times['D'] = times['created_utc'].dt.floor('D')\n",
    "    times['M'] = times['created_utc'].dt.to_period('M').dt.to_timestamp()\n",
    "    times['Y'] = times['created_utc'].dt.to_period('Y').dt.to_timestamp()\n",
    "    plot_data = times.groupby([agg_level,'domain']).agg(len).reset_index()[[agg_level,'domain','created']]\n",
    "    plot_data.columns = [agg_level,'domain','count']\n",
    "    return(px.bar(plot_data,width=width,height=height,x=agg_level,y='count',color='domain'))\n",
    "\n",
    "def author_subreddits_over_time(times,width=default_chart_width,height=default_chart_height,agg_level = agg_level):\n",
    "    times = times.sort_values('created_utc').reset_index()\n",
    "    times['D'] = times['created_utc'].dt.floor('D')\n",
    "    times['M'] = times['created_utc'].dt.to_period('M').dt.to_timestamp()\n",
    "    times['Y'] = times['created_utc'].dt.to_period('Y').dt.to_timestamp()\n",
    "    plot_data = times.groupby([agg_level,'subreddit','post_type']).agg(len).reset_index()[[agg_level,'subreddit','post_type','created']]\n",
    "    plot_data.columns = [agg_level,'subreddit','post_type','count']\n",
    "    return(px.bar(plot_data,width=width,height=height,x=agg_level,y='count',color='subreddit',facet_row='post_type'))\n",
    "\n",
    "def author_subreddits_bar(times,height=default_chart_height,width=default_chart_width):\n",
    "    plot_data = times.groupby(['subreddit','post_type']).agg(len).reset_index()[['subreddit','post_type','created']]\n",
    "    plot_data.columns = ['subreddit','post_type','count']\n",
    "    plot_data.sort_values('count', ascending=False,inplace=True)\n",
    "    return(px.bar(plot_data,y='count',color='subreddit',x='post_type',width=width,height=height))\n",
    "\n",
    "def author_to_timeseries_chart(times,height=default_chart_height,width=default_chart_width):\n",
    "    times['day']=times['created_utc'].dt.floor('D')\n",
    "    plot_dat = times.groupby(['post_type','day']).agg(len).reset_index()\n",
    "    plot_dat = plot_dat[['post_type','day','created']]\n",
    "    plot_dat.columns = ['post_type','day','count']\n",
    "\n",
    "    min_date = np.min(times['created_utc'].dt.floor('D'))\n",
    "    max_date = np.max(times['created_utc'].dt.ceil('D'))\n",
    "    all_dates = pd.DataFrame(pd.date_range(min_date,max_date,freq='D'))\n",
    "    all_dates.columns = ['day']\n",
    "    submission_dates = all_dates.copy()\n",
    "    submission_dates['post_type'] = 'submission'\n",
    "    comment_dates = all_dates.copy()\n",
    "    comment_dates['post_type'] = 'comment'\n",
    "    all_dates = pd.concat([submission_dates,comment_dates],ignore_index=True,sort=False)\n",
    "    plot_dat = plot_dat.merge(all_dates,how='right',on=['day','post_type'])\n",
    "    plot_dat = plot_dat.fillna(0)\n",
    "    plot_dat = plot_dat.sort_values('day')\n",
    "    return(px.line(plot_dat,x='day',y='count',color='post_type',title='Number of Comments and Submissons Daily',width=width,height=height))\n",
    "\n",
    "def author_time_of_day(times,width=default_chart_width,height=default_chart_height):\n",
    "    times['hr_est'] = (times.created_utc.astype(str).str[11:13].astype(int)-5) % 24\n",
    "\n",
    "    plot_data = times.groupby(['hr_est','post_type']).agg(len).reset_index()[['hr_est','post_type','created']]\n",
    "    plot_data.columns = ['hr_EST','post_type','count']\n",
    "    return(px.bar(plot_data,width=width,height=height,x='hr_EST',y='count',facet_row='post_type'))\n",
    "\n",
    "def author_day_of_week(times,width=default_chart_width,height=default_chart_height):\n",
    "    times['weekday'] = times.created_utc.dt.weekday\n",
    "    times = times.sort_values('weekday')\n",
    "    times['weekday'] = times['weekday'].map({0:'Monday',1:'Tuesday',2:'Wednesday',3:'Thursday',4:'Friday',5:'Saturday',6:'Sunday'})\n",
    "    plot_data = times.groupby(['weekday','post_type']).agg(len).reset_index()[['weekday','post_type','created']]\n",
    "    plot_data.columns = ['weekday','post_type','count']\n",
    "    return(px.bar(plot_data,width=width,height=height,x='weekday',y='count',facet_row='post_type',category_orders={'weekday':['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']}))\n",
    "\n",
    "def reddit_score_timeseries_click_plot(df,height=score_bubble_height,width=default_chart_width):\n",
    "    df['abs_score'] = np.abs(df['score'])+1\n",
    "    df['abs_score'] = 4+2*np.log2(df['abs_score'])\n",
    "    df['is_negative_score'] = (df['score']<0)\n",
    "\n",
    "    yrange = FactorRange(factors = df['subreddit'].unique())\n",
    "    MARKERS = ['circle','hex']\n",
    "    SUBMISSION = ['comment', 'submission']\n",
    "\n",
    "    p = figure(plot_width=width, plot_height=height,tools=['pan','tap','reset','box_zoom','hover'], active_drag=\"box_zoom\",\n",
    "         y_range=yrange, x_axis_type='datetime', title=\"Reddit Post Explorer\")\n",
    "\n",
    "    source = ColumnDataSource(data=dict(\n",
    "        x = df['created_utc'],\n",
    "        y = df['subreddit'],\n",
    "        x_str = pd.to_datetime(df['created_utc']).astype('str'),\n",
    "        subreddit = df['subreddit'],\n",
    "        submission = df['post_type'],\n",
    "        # \"<a href=\\\"\"+df_to_show['permalink']+\"\\\" target=\\\"_blank\\\">link</a>\" &quot; target=&quot;_blank&quot;&gt;link&lt;/a&gt;\n",
    "        permalink = df['permalink'].str.replace('^<a href=\\\"|\\\" target.*$| &quot.*$',''),\n",
    "        size=df['abs_score'],\n",
    "        title=df['title'],\n",
    "        score=df['score'],\n",
    "        text=df['text'],\n",
    "        url = df['url'],\n",
    "        color= df['is_negative_score'].map({True:'red',False:'blue'})\n",
    "        ))\n",
    "\n",
    "    p.scatter(x='x', y=jitter('y',width=0.6, range = yrange),  marker=factor_mark('submission', MARKERS, SUBMISSION), color = 'color', alpha=0.2,size='size',source=source)\n",
    "\n",
    "    hover = p.select(dict(type=HoverTool))\n",
    "    hover.tooltips = OrderedDict([\n",
    "        ('subreddit', '@subreddit'),\n",
    "        ('score', '@score'),\n",
    "        ('url', '@url'),\n",
    "        ('title', '@title'),\n",
    "        ('text', '@text'),\n",
    "        ('date', '@x_str'),\n",
    "        ('post_type','@submission')\n",
    "    ])\n",
    "\n",
    "    url = \"\"\n",
    "    taptool = p.select(type=TapTool)\n",
    "    taptool.callback = OpenURL(url='@permalink')\n",
    "    return(p)\n",
    "\n",
    "\n",
    "def author_to_karma_pies(df,width=default_chart_width,height=default_chart_height):    \n",
    "    temp = df[df.post_type=='submission'].groupby('subreddit').agg(np.sum).reset_index()\n",
    "    labels = temp['subreddit']\n",
    "    values = temp['score']\n",
    "\n",
    "    temp = df[df.post_type=='comment'].groupby('subreddit').agg(np.sum).reset_index()\n",
    "    labels2 = temp['subreddit']\n",
    "    values2 = temp['score']\n",
    "\n",
    "    # Create subplots: use 'domain' type for Pie subplot\n",
    "    fig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\n",
    "\n",
    "    fig.add_trace(go.Pie(labels=labels, values=values, name = 'Submission Score'),1,1)\n",
    "    fig.add_trace(go.Pie(labels=labels2, values=values2, name = 'Comment Score'),1,2)\n",
    "\n",
    "    fig.update_layout(\n",
    "        width=width,\n",
    "        height=height,\n",
    "        title_text=\"Karma Sources (Subreddits)\",\n",
    "        # Add annotations in the center of the donut pies.\n",
    "        annotations=[dict(text='Submissions', x=0.18, y=0.5, font_size=20, showarrow=False),\n",
    "                     dict(text='Comments', x=0.82, y=0.5, font_size=20, showarrow=False)])\n",
    "    return(fig)\n",
    "\n",
    "def get_author_history(author,min_date = default_min_date,max_date = default_max_date):\n",
    "    min_date = int(min_date.strftime(\"%s\"))\n",
    "    max_date = int(max_date.strftime(\"%s\"))\n",
    "    columns_to_get=['subreddit','created_utc','score','controversiality','url','permalink','title','domain','num_comments','num_crossposts','post_hint']\n",
    "    temp = columns_to_get\n",
    "    temp.extend(['selftext'])\n",
    "    if len(text_search_widget.value ) > 0:\n",
    "        submissions = list(api.search_submissions(author = author, after = min_date, before = max_date, q=text_search_widget.value.lower(), limit = query_limit.value, filter=temp))\n",
    "    else:\n",
    "        submissions = list(api.search_submissions(author = author,after = min_date, before = max_date, limit = query_limit.value, filter=temp))\n",
    "    submissions_len=len(submissions)\n",
    "    #print('Num Submissions:' + str(submissions_len))\n",
    "    if submissions_len>0:\n",
    "        submissions = pd.DataFrame([i.d_ for i in submissions])\n",
    "        submissions['post_type']='submission'\n",
    "    \n",
    "    temp = columns_to_get\n",
    "    temp.extend(['body','title'])\n",
    "    \n",
    "    if len(text_search_widget.value ) > 0:\n",
    "        comments = list(api.search_comments(author = author,after = min_date, before = max_date, q=text_search_widget.value.lower(),  limit = query_limit.value, filter=temp))\n",
    "    else:\n",
    "        comments = list(api.search_comments(author = author,after = min_date, before = max_date,  limit = query_limit.value, filter=temp))\n",
    "    comments_len = len(comments)\n",
    "    \n",
    "    #print('Num Comments:' + str(comments_len))\n",
    "    if comments_len>0:\n",
    "        comments = pd.DataFrame([i.d_ for i in comments])\n",
    "        comments['post_type']='comment'\n",
    "        \n",
    "    if submissions_len>0:\n",
    "        if comments_len>0:\n",
    "            df = pd.concat([submissions, comments],ignore_index=True,sort=False)\n",
    "            df['text'] = df['selftext'].combine_first(df['body'])\n",
    "            df = df.drop(columns=['body','selftext'])\n",
    "        else:\n",
    "            df = submissions\n",
    "            df['text'] = df['body']\n",
    "            df = df.drop(columns=['body'])\n",
    "    else:\n",
    "        return(pd.DataFrame([],columns=['created_utc','permalink','score','subreddit','url','created','post_type','text']))\n",
    "    df['created_utc'] = pd.to_datetime(df['created_utc'],unit='s')\n",
    "    df['permalink'] = 'https://reddit.com'+df['permalink']\n",
    "    df['title'] = df['title'].fillna('')\n",
    "    df['domain'] = df['domain'].fillna('')\n",
    "    df['post_hint'] = df['post_hint'].fillna('none')\n",
    "    df['num_crossposts'] = df['num_crossposts'].fillna(0)\n",
    "    df['num_comments'] = df['num_comments'].fillna(0)\n",
    "    return(df)\n",
    "\n",
    "def interactive_manual(f, *args, **kwargs):\n",
    "    return interactive(f, {\"manual\":True, \"auto_display\": True}, **kwargs)\n",
    "\n",
    "chart_height = widgets.IntText(value=default_chart_height,description='Chart Height')\n",
    "chart_width = widgets.IntText(value=default_chart_width,description='Chart Width')\n",
    "\n",
    "\n",
    "def update_charts(agg_level=agg_level,chart_height=chart_height.value,chart_width=chart_width.value):\n",
    "    #global mygrid\n",
    "    df = mygrid.get_changed_df()\n",
    "\n",
    "    with out:\n",
    "        clear_output()\n",
    "        test = reddit_score_timeseries_click_plot(df,width=chart_width,height=chart_height)\n",
    "        show(test)\n",
    "\n",
    "    with out2:\n",
    "        clear_output()\n",
    "        test = author_subreddits_over_time(df,agg_level=agg_level,width=chart_width,height=chart_height)\n",
    "        display(test)\n",
    "\n",
    "    with out3:\n",
    "        clear_output()\n",
    "        test = author_time_of_day(df,width=chart_width,height=chart_height)\n",
    "        display(test)\n",
    "\n",
    "    with out4:\n",
    "        clear_output()\n",
    "        test = author_day_of_week(df,width=chart_width,height=chart_height)\n",
    "        display(test)\n",
    "\n",
    "    with out5:\n",
    "        clear_output()\n",
    "        test = author_to_karma_pies(df,width=chart_width,height=chart_height)\n",
    "        display(test)\n",
    "\n",
    "    with out6:\n",
    "        clear_output()\n",
    "        test = author_to_karma_chart(df,width=chart_width,height=chart_height)\n",
    "        display(test)\n",
    "        \n",
    "    with out8:\n",
    "        clear_output()\n",
    "        test = links_over_time(df,agg_level=agg_level,width=chart_width,height=chart_height)\n",
    "        display(test)    \n",
    "\n",
    "        \n",
    "out = Output()\n",
    "out2 = Output()\n",
    "out3 = Output()\n",
    "out4 = Output()\n",
    "out5 = Output()\n",
    "out6 = Output()\n",
    "out7 = Output()\n",
    "out8 = Output()\n",
    "        \n",
    "file_link_output = Output()\n",
    "\n",
    "t = Tab(layout = Layout(display='flex',\n",
    "                    flex_flow='column',\n",
    "                    width='80%'))\n",
    "t.set_title(0,'Data Table')\n",
    "t.set_title(1,'Subreddit Timeseries')\n",
    "t.set_title(2,'Domain Timeseries')\n",
    "t.set_title(3,'Post Chart')\n",
    "t.set_title(4,'Time of Day')\n",
    "t.set_title(5,'Days of Week')\n",
    "t.set_title(6,'Karma Sources')\n",
    "t.set_title(7,'Karma Growth')\n",
    "\n",
    "t.children = [out7, out2, out8, out, out3, out4, out5, out6]\n",
    "\n",
    "author_description = widgets.HTML(\"Enter author to search for:\")\n",
    "author_box = widgets.Text(value=author)\n",
    "\n",
    "filter_button_Description = widgets.HTML(\"Apply table filters to charts\")\n",
    "\n",
    "b_filter_data = widgets.Button(description='Update Charts')\n",
    "b_fetch_data = widgets.Button(description='Fetch Data for Author')\n",
    "\n",
    "selct_date_agg_level = widgets.Dropdown(options=['D','M','Y'],value=agg_level)\n",
    "\n",
    "text_search_widget = widgets.Text('')\n",
    "query_limit = widgets.IntText(value=default_limit,description='Query Limit')\n",
    "\n",
    "\n",
    "min_date = widgets.DatePicker(\n",
    "    description='Start Date',\n",
    "    value = default_min_date,\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "max_date = widgets.DatePicker(\n",
    "    description='End Date',\n",
    "    value = default_max_date,\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "param_pane = [widgets.HTML('<h3>Query PushShift</h3>'),\n",
    "              author_description,\n",
    "              author_box,\n",
    "              query_limit,\n",
    "              widgets.HTML('Search Text'),\n",
    "              text_search_widget,\n",
    "              min_date,\n",
    "              max_date,\n",
    "              b_fetch_data,\n",
    "              widgets.HTML('<hr>'),\n",
    "              widgets.HTML('<h3>Update Charts</h3>'),\n",
    "              widgets.HTML('Date Aggregation Level'),\n",
    "              selct_date_agg_level,\n",
    "              chart_width,\n",
    "              chart_height,\n",
    "              filter_button_Description,\n",
    "              b_filter_data,\n",
    "              widgets.HTML('<hr><h3>File Download Links</h3>'),\n",
    "             file_link_output]\n",
    "\n",
    "mycolumns = widgets.HBox([widgets.VBox(param_pane,layout=Layout(display='flex',flex_flow='column',width='20%')),t])\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    update_charts(agg_level = selct_date_agg_level.value,chart_height=chart_height.value,chart_width=chart_width.value)\n",
    "    \n",
    "def on_fetch_data_button(b):\n",
    "    global df\n",
    "    df = get_author_history(author = author_box.value,min_date = min_date.value, max_date = max_date.value)\n",
    "    #global df_backup\n",
    "    #df_backup = df\n",
    "    global mygrid\n",
    "    col_defs = {\n",
    "    'text': {\n",
    "        'width': 450,\n",
    "    },\n",
    "    'index': {\n",
    "        'width': 10,\n",
    "    },\n",
    "            'permalink': {\n",
    "        'width': 80,\n",
    "    },\n",
    "            'score': {\n",
    "        'width': 80,\n",
    "    },\n",
    "        'url': {\n",
    "        'width': 250,\n",
    "    },\n",
    "            'post_type': {\n",
    "        'width': 100,\n",
    "    }\n",
    "    }\n",
    "    with out7:\n",
    "        clear_output()\n",
    "        df_to_show = df\n",
    "        df_to_show['permalink'] = \"<a href=\\\"\"+df_to_show['permalink']+\"\\\" target=\\\"_blank\\\">link</a>\"\n",
    "        df_to_show['url'] = \"<a href=\\\"\"+df_to_show['url']+\"\\\" target=\\\"_blank\\\">\"+df_to_show['url'].str.replace('^https://www\\.|^http://www\\.','',regex=True)+\"</a>\"\n",
    "        #df_to_show.set_index('created_utc', inplace=True)\n",
    "        df_to_show = df_to_show.sort_values('created_utc')\n",
    "        df_to_show['url'] = df_to_show['url'].fillna('')\n",
    "        mygrid = qgrid.show_grid(df_to_show,column_definitions=col_defs,show_toolbar=False,grid_options={'forceFitColumns': False, 'editable':False, 'maxVisibleRows': maxVisibleRows, 'minVisibleRows': 8 })\n",
    "        display(mygrid)\n",
    "    update_charts(agg_level = selct_date_agg_level.value,chart_height=chart_height.value,chart_width=chart_width.value)\n",
    "    with file_link_output:\n",
    "        df.to_csv('reddit_user_data_for_'+author_box.value+'.csv')\n",
    "        display(FileLink('reddit_user_data_for_'+author_box.value+'.csv') )\n",
    "        #FileLink('.') #lists all downloadable files on server\n",
    "        \n",
    "b_fetch_data.on_click(on_fetch_data_button)\n",
    "    \n",
    "b_filter_data.on_click(on_button_clicked)\n",
    "\n",
    "mycolumns\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
